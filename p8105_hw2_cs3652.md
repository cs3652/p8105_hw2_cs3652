HW2\_cs3652
================

GitHub Documents
----------------

This is an R Markdown format used for publishing markdown documents to GitHub. When you click the **Knit** button all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────── tidyverse 1.2.1 ──

    ## ✔ ggplot2 3.0.0     ✔ purrr   0.2.5
    ## ✔ tibble  1.4.2     ✔ dplyr   0.7.6
    ## ✔ tidyr   0.8.1     ✔ stringr 1.3.1
    ## ✔ readr   1.1.1     ✔ forcats 0.3.0

    ## ── Conflicts ───────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

Problem 1
---------

``` r
subway_data = read_csv(file = "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = "cccddcccccccccccccccccccccccddcc") %>%
  janitor::clean_names() %>% 
  ##cleaning names so that they are lowercase snake
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  ##selecting relevant variables
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))
  ##recoding to logical variable 
```

This dataset has many variables that describe the MTA service at New York City subway stations. It includes the routes that each station serves, as well as entry/exit points, and ada compliance, among many other things. Thus far, the data cleaning steps that I have taken so far are: cleaning the names so that they are easy to read and are lower case snake, selecting the columns (variables) that are relevant to our analysis, and mutating the entry variable so that it is a logical variable. The dimension of the resulting dataset is 1868, 19 (that is 1868 rows x 19 columns). These data are not entirely tidy since the route variables can be futher simplified into more usable data based on the analyses that we want to conduct.

``` r
subway_data %>% 
  distinct(line, station_name) 
```

    ## # A tibble: 465 x 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # ... with 455 more rows

``` r
  ##finding the distinct number of stations 
select(subway_data, line, station_name, ada) %>% 
  filter(ada == "TRUE") %>% 
  distinct(line, station_name, ada)
```

    ## # A tibble: 84 x 3
    ##    line            station_name                   ada  
    ##    <chr>           <chr>                          <chr>
    ##  1 4 Avenue        Atlantic Av-Barclays Ctr       TRUE 
    ##  2 4 Avenue        DeKalb Av                      TRUE 
    ##  3 4 Avenue        Pacific St                     TRUE 
    ##  4 42nd St Shuttle Grand Central                  TRUE 
    ##  5 6 Avenue        34th St                        TRUE 
    ##  6 6 Avenue        47-50th Sts Rockefeller Center TRUE 
    ##  7 6 Avenue        Church Av                      TRUE 
    ##  8 63rd Street     21st St                        TRUE 
    ##  9 63rd Street     Lexington Av                   TRUE 
    ## 10 63rd Street     Roosevelt Island               TRUE 
    ## # ... with 74 more rows

``` r
  ##finding the number of ADA compliant stations 
nrow(filter(subway_data, entry == TRUE, vending == "NO")) / nrow(filter(subway_data, vending == "NO"))
```

    ## [1] 0.3770492

``` r
  ##finding the proportion of station entrances without vending allowing entrance. 
```

According to this dataset there are 465 distinct stations. There are 84 stations that are ADA compliant. Furthermore, the proportion of stations extrances/exits, without vending, that allow entrance is 0.3770492 or 37.7%.

``` r
subway_data_tidy = (gather(subway_data, key = route_number, value = route, route1:route11)) 
#creating a new dataframe where route number information is simplified
```

``` r
nrow(filter(distinct(subway_data_tidy, line, station_name, route), route == "A"))
```

    ## [1] 60

``` r
nrow(filter(distinct(subway_data_tidy, line, station_name, route, ada), route == "A", ada == TRUE))
```

    ## [1] 17

There are 60 stations on the A line. Only 17 of the 60 stations are ADA compliant.

Problem 2

This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website. Please use the HealthyHarborWaterWheelTotals2017-9-26.xlsx version.

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit columns containing notes (using the range argument and cell\_cols() function) use reasonable variable names omit rows that do not include dumpster-specific data rounds the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016? Problem 3

This problem uses the BRFSS data. DO NOT include this dataset in your local data directory; instead, load the data from the p8105.datasets package.

For this question:

format the data to use appropriate variable names; focus on the “Overall Health” topic exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data\_value in the original dataset) create a new variable showing the proportion of responses that were “Excellent” or “Very Good”

Using this dataset, do or answer the following:

How many unique locations are included in the dataset? Is every state represented? What state is observed the most? In 2002, what is the median of the “Excellent” response value? Make a histogram of “Excellent” response values in the year 2002. Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.
